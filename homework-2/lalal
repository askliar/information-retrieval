from collections import defaultdict
import os
import scipy.stats
import matplotlib.pyplot as plt

def validation_best(score_name, param_list, measures):
    result_dicts = []
    for p in param_list:
        
        result_dicts.append(trec_eval(score_name + ('_' + str(p) if p != None else ''), measures, validation=True))
    vals = []
    for res in result_dicts:
#         print(res)
        vals.append(res['ndcg_cut_10']['all'])
    best = np.argmax(vals)
    return best, vals[best], param_list[best], result_dicts[best], result_dicts
    
def trec_eval(score_name, measures, validation=True):
    validation_str = 'validation' if validation else 'test'
    results = defaultdict(dict)
    a = os.system(str.format('./trec_eval/trec_eval -m all_trec -q ap_88_89/qrel_{} {}.run > trec_results_{}', validation_str, score_name, score_name))
    f = open('results/trec_results_' + score_name, 'r')
    for line in f.readlines():
        name, id, val = line.strip().split()
        if name in measures:
            val = float(val)
            results[name][id] = val

    f.close()
    return results

kernel_names = ['gauss', 'triangle', 'circle', 'cosine', 'passage']
measures = ['ndcg_cut_10', 'map_cut_1000', 'recall_1000', 'P_5']
scores = ['jelinek_mercer','abs_discounting', 'dirichlet_prior', 'tfidf', 'bm25']
plm_names = ['plm-' + kernel_name for kernel_name in kernel_names]

scores = scores + plm_names
params = {'jelinek_mercer': [0.1, 0.5, 0.9],
         'abs_discounting': [0.1, 0.5, 0.9],
         'dirichlet_prior': [500, 1000, 1500],
          'tfidf': [None], 'bm25': [None]}
for i, name in enumerate(plm_names):
    params[name] = [0.1, 0.5, 0.9]
    
ind = np.arange(len(measures))
width = 0.08
colors = ['r', 'g', 'b', 'y', 'k', 'grey', 'purple', 'orange', 'pink']
colors = colors + colors + colors + colors
fig, ax = plt.subplots()
rs = []
#evaluation measures on with optimized hyper parameters
bests = dict()
for i, score in enumerate(scores):
    best, best_val, best_param, best_result, results = validation_best(score, params[score], measures)
    bests[score] = best_param
    means = [best_result[measure]['all'] for measure in measures]
    rs.append(ax.bar(ind + width*i, means, width, color=colors[i]))
# print(bests)
ax.legend(rs, scores)
ax.set_ylabel('Scores')
ax.set_title('Scores measure')
ax.set_xticks(ind + width*10 / 2)
ax.set_xticklabels(measures)
plt.show()


ind = np.arange(3)
width = 0.08
fig, ax = plt.subplots()
rs = []
result_dicts = defaultdict(dict)
for i, score in enumerate(scores):
#     if score in params:
    for p in params[score]:
        result_dicts[score][p] = trec_eval(score + ('_' + str(p) if p != None else ''), measures, validation=False)
#     else:
#         print('we')
#         results_dicts[score][None] = trec_eval(score, measures, validation=False)
#     print(result_dicts[score])
    means = [result_dicts[score][p]['ndcg_cut_10']['all'] for p in result_dicts[score]]
    print(score)
    markers_on = [i for i, _ in enumerate(params[score])]
    plt.plot(means, markevery=markers_on)
    plt.show()


import pandas
pairwise = defaultdict(dict)
for score in scores:
    for score2 in scores:
        pairwise[score][score2] = scipy.stats.ttest_rel(list(result_dicts[score][bests[score]]['ndcg_cut_10'].values()), 
                                     list(result_dicts[score2][bests[score2]]['ndcg_cut_10'].values()))
        # here we should compare to our p value to decide the significance
#         print('result of ', score, ' with score ', param, 'respect to ', score2, 'is ', a, p)
df = pandas.DataFrame.from_dict(pairwise)        
print(df)
