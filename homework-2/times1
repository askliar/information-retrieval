Timer unit: 1e-06 s

Total time: 56.5512 s
File: kernelopt.py
Function: run_retrieval at line 505

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   505                                           @profile
   506                                           def run_retrieval(model_name, score_fn):
   507                                               """
   508                                               Runs a retrieval method for all the queries and writes the TREC-friendly results in a file.
   509                                               
   510                                               :param model_name: the name of the model (a string)
   511                                               :param score_fn: the scoring function (a function - see below for an example) 
   512                                               """
   513         1          3.0      3.0      0.0      run_out_path = '{}.run'.format(model_name)
   514                                           
   515                                           #     if os.path.exists(run_out_path):
   516                                           #         return
   517                                           
   518         1          1.0      1.0      0.0      retrieval_start_time = time.time()
   519                                           
   520         1         20.0     20.0      0.0      print('Retrieving using', model_name)
   521                                               
   522         1         14.0     14.0      0.0      data = collections.defaultdict(list)
   523                                               # The dictionary data should have the form: query_id --> (document_score, external_doc_id)
   524         1          1.0      1.0      0.0      count = 0
   525         1          2.0      2.0      0.0      for query_id in tokenized_queries:
   526                                                       
   527         1          2.0      2.0      0.0          if count % 15 == 0:
   528         1         11.0     11.0      0.0              print('Finished {}%...'.format(count / 15 * 10))
   529         1          1.0      1.0      0.0          count += 1    
   530         1          1.0      1.0      0.0          doc_result = []
   531      2843       2331.0      0.8      0.0          for int_doc_id in document_ids:
   532      2843      67658.0     23.8      0.1              ext_doc_id, _ = index.document(int_doc_id)
   533      2843   56477875.0  19865.6     99.9              doc_score = score_fn(int_doc_id, query_id)
   534                                           #             if doc_score != 0:
   535      2842       3242.0      1.1      0.0              data[query_id].append((doc_score, ext_doc_id))
   536                                                   
   537                                               with open(run_out_path, 'w') as f_out:
   538                                                   write_run(
   539                                                       model_name=model_name,
   540                                                       data=data,
   541                                                       out_f=f_out,
   542                                                       max_objects_per_query=1000)

Total time: 31.3061 s
File: kernelopt.py
Function: positional_language_model at line 824

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   824                                           @profile
   825                                           def positional_language_model(int_document_id, query_id, kernel, kernel_integral, mu=0.1):
   826      2843      11045.0      3.9      0.0      all_scores = np.zeros(document_lengths[int_document_id])
   827     14211      13264.0      0.9      0.0      for query_term_id in set(tokenized_queries[query_id]):    
   828   2971070    1742481.0      0.6      5.6          for i in range(document_lengths[int_document_id]):
   829   2959702    1719147.0      0.6      5.5              term_score = 0
   830   2959702    1756713.0      0.6      5.6              score = 0
   831   2959702    2132380.0      0.7      6.8              if int_document_id in inverted_index_positions[query_term_id]:
   832    674479     432740.0      0.6      1.4                  for query_term_pos in inverted_index_positions[query_term_id][int_document_id]:
   833    452804     738565.0      1.6      2.4                      term_score += kernel[np.abs(i-query_term_pos)]
   834                                                           #NEXT LINE
   835                                                           #TODO: check this
   836    221675     217610.0      1.0      0.7                  term_score = min(term_score, 1.0)
   837                                                       else:
   838   2738027    1602249.0      0.6      5.1                  term_score = 0
   839   2959702    2811712.0      0.9      9.0              prob_query = query_term_counts[query_id][query_term_id]/len(tokenized_queries[query_id])
   840   2959701    2013744.0      0.7      6.4              prob = collection_frequencies[query_term_id]/total_terms
   841   2959701    1834233.0      0.6      5.9              doc_len = document_lengths[int_document_id] 
   842   2959701    2984200.0      1.0      9.5              norm_value = kernel_integral[i] + kernel_integral[document_lengths[int_document_id]-1-i]
   843                                                       #NEXT LINE
   844   2959701    2662948.0      0.9      8.5              prob_word = (term_score+mu*prob)/(norm_value + mu)
   845                                                       #NEXT LINE
   846   2959701    6034044.0      2.0     19.3              score = prob_query * np.log(prob_query/prob_word)
   847                                           #                 assert prob_word <= 1.0
   848   2959701    2548308.0      0.9      8.1              all_scores[i] += score
   849      2842      17013.0      6.0      0.1      all_scores *= -1    
   850      2842      31610.0     11.1      0.1      score = np.max(all_scores)
   851      2842       2071.0      0.7      0.0      return score

